What is horizontal scaling (scaling out)?	Adding more machines to distribute load. Requires stateless services or shared state (e.g., via a cache or database). More fault-tolerant than vertical scaling.
What is vertical scaling (scaling up)?	Adding more resources (CPU, RAM) to an existing machine. Simpler to implement but has a hardware ceiling and a single point of failure.
What is a load balancer?	A component that distributes incoming traffic across multiple backend servers. Algorithms: round robin, least connections, IP hash. Improves availability and throughput.
What is caching?	Storing the result of expensive operations in fast storage so future requests can be served faster. Common layers: in-memory (Redis), CDN, browser cache, database query cache.
What is a CDN (Content Delivery Network)?	A geographically distributed network of servers that caches static assets (images, JS, CSS) close to end users to reduce latency and origin server load.
What is database sharding?	Horizontally partitioning data across multiple database nodes (shards). Each shard holds a subset of the data. Increases write throughput but complicates queries and transactions.
What is database replication?	Copying data from a primary (leader) database to one or more replicas (followers). Read replicas improve read throughput; replication lag is a consistency trade-off.
What is the difference between read replicas and sharding?	Read replicas: all nodes have a full copy — scale reads only.<br>Sharding: each node has a partial copy — scales both reads and writes but splits data.
What is eventual consistency?	A consistency model where all replicas will converge to the same value given enough time with no new updates. Common in distributed systems that prioritize availability (AP in CAP).
What is a message queue?	An asynchronous communication buffer between services. Producers publish messages; consumers process them independently. Decouples services and absorbs traffic spikes. Examples: Kafka, RabbitMQ, SQS.
What is the difference between a message queue and pub/sub?	Queue: one consumer receives each message (point-to-point, work distribution).<br>Pub/Sub: all subscribers receive every message (broadcast, event notification). Examples: Kafka supports both.
What is rate limiting?	Controlling how many requests a client can make in a given time window to prevent abuse and protect system resources. Algorithms: token bucket, leaky bucket, sliding window.
What is a circuit breaker?	A design pattern that stops requests to a failing service after a threshold of errors, allowing it to recover. States: Closed (normal), Open (fail fast), Half-Open (test recovery).
What is an API gateway?	A single entry point for client requests that handles routing, authentication, rate limiting, SSL termination, and request aggregation before forwarding to backend services.
What is the difference between SQL and NoSQL for system design?	SQL: strong consistency, ACID, complex queries, vertical scaling. Choose for financial data, relational models.<br>NoSQL: flexible schema, horizontal scaling, eventual consistency. Choose for high write throughput, unstructured data.
What is consistent hashing?	A technique for distributing keys across a ring of nodes such that adding or removing a node only remaps a small fraction of keys. Used in distributed caches and databases (e.g., Cassandra, DynamoDB).
What is a reverse proxy?	A server that sits in front of backend servers and forwards client requests to them. Provides SSL termination, load balancing, caching, and hides backend topology. Example: Nginx.
What is the difference between latency and throughput?	Latency: time to process a single request (lower is better).<br>Throughput: number of requests processed per unit time (higher is better). Optimizing one often trades off the other.
What is a microservices architecture?	Structuring an application as a collection of small, independently deployable services, each responsible for a specific business capability, communicating over APIs or message queues.
What is the two-phase commit (2PC)?	A distributed transaction protocol ensuring all participating nodes either commit or roll back. Phase 1: coordinator asks all nodes to prepare. Phase 2: coordinator sends commit or abort based on responses.
